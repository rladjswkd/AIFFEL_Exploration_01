{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIL 라이브러리가 설치되어있지 않다면 설치하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (8.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가위, 바위, 보 jpg 이미지를 경로로부터 가져와서 28 x 28 사이즈로 변경하는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(path):\n",
    "    image_dir_path = os.getenv(\"HOME\") + path\n",
    "    images = glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img,\"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_image(\"/aiffel/rock_scissor_paper_training/scissor\")\n",
    "resize_image(\"/aiffel/rock_scissor_paper_training/rock\")\n",
    "resize_image(\"/aiffel/rock_scissor_paper_training/paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 데이터를 가져와 행렬에 담는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, number_of_data):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 이미지 데이터를 load_data 메서드로 전달해 행렬을 반환받은 후, 각 요소의 값을 0 ~ 1 사이의 값으로 정규화하는 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_training\"\n",
    "(x_train, y_train)=load_data(image_dir_path, 2400)\n",
    "\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력 데이터와 출력 데이터가 하나므로 Sequential model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(256, (3,3), activation = 'relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPooling2D(2,2))\n",
    "model.add(keras.layers.Conv2D(512, (3,3), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2,2))\n",
    "model.add(keras.layers.Conv2D(512, (3,3), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(2,2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델을 학습시키는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "75/75 [==============================] - 13s 169ms/step - loss: 1.0770 - accuracy: 0.3896\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 13s 170ms/step - loss: 0.8260 - accuracy: 0.6004\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 13s 175ms/step - loss: 0.5100 - accuracy: 0.8008\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 13s 176ms/step - loss: 0.2878 - accuracy: 0.8917\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 13s 176ms/step - loss: 0.1949 - accuracy: 0.9267\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 13s 176ms/step - loss: 0.0883 - accuracy: 0.9704\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 13s 176ms/step - loss: 0.0636 - accuracy: 0.9800\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 13s 176ms/step - loss: 0.0513 - accuracy: 0.9812\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 13s 176ms/step - loss: 0.0179 - accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 14s 181ms/step - loss: 0.0028 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a4e593350>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터셋의 크기를 28 x 28로 변경하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_image(\"/aiffel/rock_scissor_paper_test/scissor\")\n",
    "resize_image(\"/aiffel/rock_scissor_paper_test/rock\")\n",
    "resize_image(\"/aiffel/rock_scissor_paper_test/paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터의 각 요소 값을 0 ~ 1 사이로 정규화하는 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_test\"\n",
    "(x_test, y_test)=load_data(image_dir_path, 300)\n",
    "\n",
    "x_test_norm = x_test/255.0  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.5467 - accuracy: 0.7433\n",
      "loss : 0.546729326248169\n",
      "accuracy : 0.7433333396911621\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose = 2)\n",
    "print(\"loss : {}\".format(test_loss))\n",
    "print(\"accuracy : {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 루브릭 평가 요구 사항에 대한 기록\n",
    "#### 1. 이미지 분류기 모델이 성공적으로 만들어졌는가?\n",
    "\n",
    "    10회의 epoch 동안 계속해서 loss function 값이 줄어들어 최종적으로 0.0028이 되었고, accuracy가 1이 되어 학습 자체는 성공적으로 이루어졌다고 볼 수 있다.\n",
    "#### 2. 오버 피팅을 극복하기 위한 적절한 시도가 있었는가?\n",
    "    \n",
    "    학습데이터와 테스트 데이터 모두 행렬의 요소 값을 0 ~ 1 사이의 값으로 정규화했다.\n",
    "    조원들의 이미지를 모두 취합해 프로젝트 요구사항인 300개의 이미지 데이터보다 더 많은 총 2700개의 데이터 셋을 활용했다.\n",
    "    (학습 데이터 2400, 테스트 데이터 300개)\n",
    "    \n",
    "#### 3. 분류 모델의 test accuracy가 기준 이상 높게 나왔는가?\n",
    "\n",
    "    결론적으로 정확도는 74% 정도가 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고\n",
    "***\n",
    "### 1. 과정\n",
    "\n",
    "초매개변수값을 MNIST코드와 유사하게 낮은 수로 설정하면 test accuracy가 낮게 나온다.\n",
    "\n",
    "처음 시도한 학습 데이터가 가위 100개 바위 100개 보 100개였기 때문에 데이터의 수가 지나치게 적어서 그런가 하고 팀원분들의 학습데이터도 포함시켜 총 2700개의 학습데이터를 사용해도 정확도는 비슷했다.\n",
    "\n",
    "앞의 설명을 읽어보면 여기서의 초매개변수들은 이미지에서의 \"특징\"을 의미한다고 한다.\n",
    "\n",
    "이 점을 고려하면서 MNIST 이미지와 가위바위보 이미지를 비교해보면 일단 흑백 이미지와 컬러 이미지의 차이가 있고, 정확하게 배경과 숫자가 구분되는 MNIST 이미지와 다르게 우리가 직접 촬영한 가위바위보 사진은 각자가 배경 사진도 다르고 누구는 어둡고 누구는 밝은 등 여러 차이가 있었다.\n",
    "\n",
    "그래서 더 많은 특징을 가지고 이미지의 라벨을 예측해야 한다고 생각했다.\n",
    "\n",
    "그래서 초매개변수 값들을 계속해서 높게 설정하며 모델 초기화 - 학습 - 테스트 과정을 반복했는데 어느 지점까지는 정확도가 올라갔지만 이 방법도 정확도 60을 넘기기 어려웠다.\n",
    "\n",
    "이후에 계속해서 이것 저것 시도를 해보다가, 초매개변수 값을 MNIST보다 높게 유지하면서 Conv2D, MaxPooling2D 레이어를 하나씩 더 추가하니까 정확도가 60이 넘었다.\n",
    "\n",
    "### 2. 생각\n",
    "\n",
    "- **좋은, 균일한 데이터의 필요성**\n",
    "\n",
    "    학습 과정에서는 정확도가 1에 가까웠지만, 테스트 과정에서 최대 74퍼센트의 정확도가 출력됐다.\n",
    "    앞에서 학습한 overfitting이 발생한 것 같은데, 입력 이미지 데이터에 정확하게 손 모양만 있는 것이 아니라 배경과 빛 등 다양한 조건에서 촬영한 사진을 모아서 학습 데이터로 사용했기 때문에 가위, 바위, 보 손 모양 이외의 다양한 \"특징\"들을 학습했기 때문이라고 생각한다.\n",
    "    정확하게 맞는 이유인지는 아직 더 공부가 필요할 것 같다.\n",
    "    \n",
    "       \n",
    "- **overfitting 회피**\n",
    "    \n",
    "    구글 검색과 약간의 사전지식으로 기억하기에 overfitting을 방지하기 위한 방법이 몇 가지 있는 것으로 알고있다.\n",
    "    당장 생각나는 것으로 dropout 방법이 있는데, 너무 많은 특징을 학습해 \"학습 데이터에 너무 잘 맞춰진\" 모델이 되는 것을 예방하기 위해 일부러 몇 가지 feature들을 학습하지 않는 것으로 알고있다. '이렇게 하면 제대로 학습이 될까' 하는 생각이 들지만 이후 학습 과정에서 정확하게 이해할 수 있는 기회가 있으면 좋겠다.\n",
    "    \n",
    "       \n",
    "- **레이어의 의미**\n",
    "\n",
    "    Conv2D 레이어와 Maxpooling2D 레이어를 하나씩 추가했더니, 오르지 않던 정확도가 올랐다.\n",
    "    그래서 한 쌍을 더 추가했더니 정확도가 오히려 떨어졌다.\n",
    "    알기로는 '필터'를 통해서 특징을 추출하기 위한 것이 이 레이어들이라고 한다.\n",
    "    레이어의 수도 초매개변수처럼 여러 번의 실험을 통해 정하는 것이 맞는 것인지, 일종의 기준이 있는지를 찾아보니 일반적으로 분류하고자 하는 이미지의 객체가 얼마나 복잡한 것인지에 따라 다르다고 한다.\n",
    "    두 쌍의 Conv2D, MaxPooling2D 레이어로는 특징을 충분히 잡지 못해서 세 쌍이 필요했고 네 쌍은 너무 많은 특징을 잡아서 테스트 정확도가 낮은 것이었는지를 더 찾아봐야 할 것 같다.\n",
    "    \n",
    "- **차원의 저주?**\n",
    "\n",
    "    모델 초기화 - 학습 - 테스트를 여러 번 반복하면 정확도가 60 ~ 81 사이를 왔다갔다한다.\n",
    "    데이터의 차원을 채울만큼의 충분한 데이터가 없어서 그런 것이 아닐까 추측하고 있다.\n",
    "    이 부분도 공\n",
    "    \n",
    "### 3. 결론\n",
    "\n",
    "회고글을 작성하면서 막연하게 엉켜있던 의문들이 어떤 것인지는 대략적으로 정리가 됐다.\n",
    "\n",
    "다만 검색을 통해 문제를 해결하고 모델이 동작한다고 해도 이게 왜 되는 것인지, 무엇을 이해해야 하는지를 알지는 못하는 것 같다.\n",
    "\n",
    "인공지능의 많은 부분들이 이론적이기 보단 경험적인 성향이 강한 것 같아서 동작하는 이유를 찾기가 더 어려웠다.\n",
    "\n",
    "게다가 초매개변수, 레이어의 수 등 어떤 것도 고치지 않고 모델을 초기화한 후 다시 학습 및 테스트를 수행하면 정확도가 10퍼센트 정도 차이가 났었다.\n",
    "\n",
    "데이터가 고르지 않아서 그 때마다 다른 특징을 학습하기 때문이 아닐까 하고 추측은 하고 있지만, 앞으로 더 많은 공부가 필요할 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
